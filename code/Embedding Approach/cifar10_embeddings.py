# -*- coding: utf-8 -*-
"""CIFAR10_embeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14cyX2M5hFxgphBPvOwvdUpv70qrTgyia
"""

import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.axis('off')
plt.show()


# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

#Import pre-trained CNN model if needed
model = tf.keras.models.load_model('model_CNN.h5')
# Show the model architecture
model.summary()


#load the dataset of missclassified examples of a specific class
import pickle

with open('my_dataset_cifar10.pickle', 'rb') as data: #change data name according to the file name
    dataset = pickle.load(data)


#Load VGG16 pre-trained model
from keras.preprocessing import image
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
import numpy as np
import cv2

model = VGG16(weights='imagenet', include_top=False)

#Pre-process data for VGG16
def pre_process_data(dataset):

  new_dataset = np.ones((dataset.shape[0], 25088))
  for i in range(dataset.shape[0]):
    res = cv2.resize(dataset[i], dsize=(224, 224), interpolation=cv2.INTER_CUBIC)
    res = np.expand_dims(res, axis=0)

    res = preprocess_input(res)
    stacked_img = np.stack((res,), axis=-1)
    # print(stacked_img.shape)
    a = model.predict(stacked_img)
    a = a.flatten()
    new_dataset[i] = a

  return new_dataset

new_data = pre_process_data(dataset)

"""Applying Kmeans on the false trained data

"""

from sklearn.cluster import KMeans
k_means = KMeans(init = 'k-means++', n_clusters = 5, n_init = 35)
k_means.fit(new_dataset)

G = len(np.unique(k_means.labels_)) #Number of labels
#2D matrix  for an array of indexes of the given label
cluster_index= [[] for i in range(G)]
for i, label in enumerate(k_means.labels_,0):
    for n in range(G):
        if label == n:
            #print(n)
            #print(i)
            cluster_index[n].append(i)
        else:
            continue

len(cluster_index[0])

"""Visualizing the created clusters"""

"""Cluster 0"""

f, axarr = plt.subplots(nrows=1, ncols=10 , figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(train_false_images[cluster_index[0][i]])

images0 = []
for h in range(len(cluster_index[0])):
  images0.append(train_false_images[cluster_index[0][h]])

avg0 = sum(images0) / len(images0)
plt.imshow(avg0)

"""Cluster 1"""

f, axarr = plt.subplots(nrows=1, ncols=10 , figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(train_false_images[cluster_index[1][i]])

images0 = []
for h in range(len(cluster_index[1])):
  images0.append(train_false_images[cluster_index[1][h]])

avg0 = sum(images0) / len(images0)
plt.imshow(avg0)

"""Cluster 2"""

f, axarr = plt.subplots(nrows=1, ncols=10 , figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(train_false_images[cluster_index[2][i]])

cluster_index[2][0]

images0 = []
for h in range(len(cluster_index[2])):
  images0.append(train_false_images[cluster_index[2][h]])

avg0 = sum(images0) / len(images0)
plt.imshow(avg0)

"""Cluster 3"""

f, axarr = plt.subplots(nrows=1, ncols=10 , figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(train_false_images[cluster_index[3][i]])

images0 = []
for h in range(len(cluster_index[3])):
  images0.append(train_false_images[cluster_index[3][h]])

avg0 = sum(images0) / len(images0)
plt.imshow(avg0)

"""Cluster 4"""

f, axarr = plt.subplots(nrows=1, ncols=10 , figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(train_false_images[cluster_index[4][i]])

images0 = []
for h in range(len(cluster_index[4])):
  images0.append(train_false_images[cluster_index[4][h]])

avg0 = sum(images0) / len(images0)
plt.imshow(avg0)

new_dataset.shape

# Similarity calculation using cosine distance function
from scipy import spatial
x=new_dataset
sim = np.ones((x.shape[0]))
k = 2
for i in range(x.shape[0]):
  y = spatial.distance.cosine(x[k], x[i])
  sim[i] = y
q = np.argsort(sim)

q

f, axarr = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))

plt.imshow(train_false_images[k]) 

f, axarr = plt.subplots(nrows=1, ncols=15, figsize=(15, 9))
for i in range(15):
  axarr[i].imshow(train_false_images[q[i]])
