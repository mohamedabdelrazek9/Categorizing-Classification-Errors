# -*- coding: utf-8 -*-
"""Autoencoder_cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S1bvXaa56ej5IV_XiceaJYVRmwCozfK-
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Conv2D, Input, Dense, Reshape, Conv2DTranspose, Activation, BatchNormalization, ReLU, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.datasets import cifar100, cifar10
import tensorflow.keras as keras

(train_data_clean, _), (test_data_clean, _) = cifar10.load_data()

train_data_clean = train_data_clean.astype('float32') / 255.
test_data_clean = test_data_clean.astype('float32') / 255.

def add_noise_and_clip_data(data):
   noise = np.random.normal(loc=0.0, scale=0.1, size=data.shape)
   data = data + noise
   data = np.clip(data, 0., 1.)
   return data
   
train_data_noisy = add_noise_and_clip_data(train_data_clean)
test_data_noisy = add_noise_and_clip_data(test_data_clean)

idx = 4
plt.subplot(1,2,1)
plt.imshow(train_data_clean[idx])
plt.title('Original image')
plt.subplot(1,2,2)
plt.imshow(train_data_noisy[idx])
plt.title('Image with noise')
plt.show()

def conv_block(x, filters, kernel_size, strides=2):
   x = Conv2D(filters=filters,
              kernel_size=kernel_size,
              strides=strides,
              padding='same')(x)
   x = BatchNormalization()(x)
   x = ReLU()(x)
   return x

def deconv_block(x, filters, kernel_size):
   x = Conv2DTranspose(filters=filters,
                       kernel_size=kernel_size,
                       strides=2,
                       padding='same')(x)
   x = BatchNormalization()(x)
   x = ReLU()(x)
   return x

def denoising_autoencoder():
   dae_inputs = Input(shape=(32, 32, 3), name='dae_input')
   conv_block1 = conv_block(dae_inputs, 32, 3)
   conv_block2 = conv_block(conv_block1, 64, 3)
   conv_block3 = conv_block(conv_block2, 128, 3)
   conv_block4 = conv_block(conv_block3, 256, 3)
   conv_block5 = conv_block(conv_block4, 256, 3, 1)

   deconv_block1 = deconv_block(conv_block5, 256, 3)
   merge1 = Concatenate()([deconv_block1, conv_block3])
   deconv_block2 = deconv_block(merge1, 128, 3)
   merge2 = Concatenate()([deconv_block2, conv_block2])
   deconv_block3 = deconv_block(merge2, 64, 3)
   merge3 = Concatenate()([deconv_block3, conv_block1])
   deconv_block4 = deconv_block(merge3, 32, 3)

   final_deconv = Conv2DTranspose(filters=3,
                       kernel_size=3,
                       padding='same')(deconv_block4)
   dae_outputs = Activation('sigmoid', name='dae_output')(final_deconv)
  
   return Model(dae_inputs, dae_outputs, name='dae')

dae = denoising_autoencoder()
dae.compile(loss='mse', optimizer='adam')

checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, save_weights_only=True)

dae.fit(train_data_noisy,
       train_data_clean,
       validation_data=(test_data_noisy, test_data_clean),
       epochs=5,
       batch_size=128,
       callbacks=[checkpoint])


#run this directly after uploading it to colab
model = tf.keras.models.load_model('Auto_test2.h5')

import pickle
#choose the dataset of the specific class and run (check always if the correct name is typed)
with open('my_dataset_cifar10.pickle', 'rb') as data:
    dataset = pickle.load(data)

model.summary()

from keras.models import Model
new_model = Model(inputs=model.input, outputs=model.layers[14].output)

#reshape data and flatten
x = new_model.predict(dataset)
x = x.reshape(dataset.shape[0], 2*2*256)

#**PCA + TSNE visualization**

from sklearn.decomposition import PCA
pca = PCA(n_components=100, random_state=22)
pca.fit(new_data)
pca_x = pca.transform(new_data)

#Import TSNE
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0).fit_transform(pca_x)

tx, ty = tsne[:,0], tsne[:,1]
tx = (tx-np.min(tx)) / (np.max(tx) - np.min(tx))
ty = (ty-np.min(ty)) / (np.max(ty) - np.min(ty))


import matplotlib.pyplot as plt
from PIL import Image
width = 2500
height = 1000
max_dim = 100
full_image = Image.new('RGB', (width, height))
#use for the for loop the uploaded dataset 
for idx, x in enumerate(dataset):
    tile = Image.fromarray(np.uint8(x * 255))
    rs = max(1, tile.width / max_dim, tile.height / max_dim)
    tile = tile.resize((int(tile.width / rs),
                        int(tile.height / rs)),
                       Image.ANTIALIAS)
    full_image.paste(tile, (int((width-max_dim) * tx[idx]),
                            int((height-max_dim) * ty[idx])))
plt.figure(figsize = (16,20))
plt.imshow(full_image)


#Elbow Method
from sklearn.cluster import KMeans
distortions = []
K = range(1,10)
for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(new_data)
    distortions.append(kmeanModel.inertia_)

plt.figure(figsize=(16,8))
plt.plot(K, distortions, 'bx-')
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.show()


#**Applying kmeans**

from sklearn.cluster import KMeans
k_means = KMeans(n_clusters = 5, random_state=0)
k_means.fit(x)
label = k_means.fit_predict(new_data)


#Getting unique labels
 
u_labels = np.unique(label)
 
#plotting the results:
 
for i in u_labels:
    plt.scatter(new_data[label == i , 0] , new_data[label == i , 1] , label = i)
plt.legend()
plt.show()


#Build cluster indexes
G = len(np.unique(k_means.labels_)) #Number of labels
#2D matrix  for an array of indexes of the given label
cluster_index= [[] for i in range(G)]
for i, label in enumerate(k_means.labels_,0):
    for n in range(G):
        if label == n:
            #print(n)
            
            cluster_index[n].append(i)
        else:
            continue

f, axarr = plt.subplots(nrows=1, ncols=10, figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(dataset[cluster_index[0][i]])

"""Unfounatly calculating the avg of all cluster images to visualize the categorical error will not work with cifar10 well, we need to find another approach"""

images0 = []
for h in range(len(cluster_index[0])):
  images0.append(dataset[cluster_index[0][h]])

avg0 = sum(images0) / len(images0)
plt.imshow(avg0)

cluster_index[1][0]

f, axarr = plt.subplots(nrows=1, ncols=13, figsize=(15, 9))
for i in range(13):
  axarr[i].imshow(dataset[cluster_index[1][i]])

f, axarr = plt.subplots(nrows=1, ncols=17, figsize=(15, 9))
for i in range(17):
  axarr[i].imshow(dataset[cluster_index[2][i]])

f, axarr = plt.subplots(nrows=1, ncols=10, figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(dataset[cluster_index[3][i]])

f, axarr = plt.subplots(nrows=1, ncols=10, figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(dataset[cluster_index[4][i]])

"""**Similarity calculation using cosine distance function**"""

from scipy import spatial

sim = np.ones((x.shape[0]))
k = 1
for i in range(x.shape[0]):
  y = spatial.distance.cosine(x[k], x[i])
  sim[i] = y
q = np.argsort(sim)

"""First photo is the query, the goal here is to calculate similarity between the query image and all the images in the small dataset we created 
and return back the first 9 results in the dataset that is similar to the dataset to make sure that the learned features by the autoencoders make sense
"""

f, axarr = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))

plt.imshow(dataset[k]) 

f, axarr = plt.subplots(nrows=1, ncols=10, figsize=(15, 9))
for i in range(10):
  axarr[i].imshow(dataset[q[i]])


"""**Saliency Maps**"""

model2 = tf.keras.models.load_model('model_CNN.h5')

def get_saliency(img):
  img = img.reshape((1, *img.shape))

  images = tf.Variable(img, dtype=float)

  with tf.GradientTape() as tape:
      pred = model2(images, training=False)
      class_idxs_sorted = np.argsort(pred.numpy().flatten())[::-1]
      
      loss = pred[0][class_idxs_sorted[0]]

  grads = tape.gradient(loss, images)

  dgrad_abs = tf.math.abs(grads)

  dgrad_max_ = np.max(dgrad_abs, axis=3)[0]

  ## normalize to range between 0 and 1
  arr_min, arr_max  = np.min(dgrad_max_), np.max(dgrad_max_)
  grad_eval = (dgrad_max_ - arr_min) / (arr_max - arr_min + 1e-18)

  return grad_eval


#Just an example we showing the first cluster but further clusters can be added
j = 1 #pick the cluster number 
all_saliency2 = np.zeros((len(cluster_index[j]), 32, 32))
for i in range(len(cluster_index[j])):
  img = dataset[cluster_index[j][i]]
  saliency = get_saliency(img)
  all_saliency2[i, :, :] = saliency


images2 = []
for h in range(all_saliency2.shape[0]):
  images2.append(all_saliency2[h])

avg2 = sum(images2) / len(images2) #calculate average of the calculated saliency maps
#plt.imshow(avg2, cmap="jet")


#for normal avg
images2_avg = []
for h in range(len(cluster_index[1])):
  images2_avg.append(dataset[cluster_index[1][h]])

avg2_1 = sum(images2_avg) / len(images2_avg) #average of images 
#plt.imshow(avg5_1)

fig, axes = plt.subplots(1,2,figsize=(14,5))
axes[0].imshow(avg2_1)
axes[1].imshow(avg2, cmap="jet", alpha=0.8)


##Normalization

def calculate_avg_saliency(data):
  all_data_saliency = np.zeros((data.shape[0], 32, 32))
  for i in range(data.shape[0]):
    img = data[i]
    saliency = get_saliency(img)
    all_data_saliency[i, :, :] = saliency

  images2 = []
  for h in range(all_data_saliency.shape[0]):
    images2.append(all_data_saliency[h])

  avg2 = sum(images2) / len(images2)

  return avg2

x = calculate_avg_saliency(train_data_clean)


#show the normalization on the first cluster
new_avg = avg1 - x


fig, axes = plt.subplots(1,2,figsize=(10,13))

axes[0].imshow(avg1, cmap="bwr", vmin=np.min(avg1), vmax=np.max(avg1))
axes[1].imshow(new_avg, cmap="bwr", vmin=np.min(new_avg), vmax=np.max(new_avg))


#Superimposing approach

#for now is most of the Saliency maps have a standrad range from 0 to 1
# not needed ??
def Normalize_data_and_show(data):
  return (data - np.min(data)) / (np.max(data) - np.min(data))


def show_new_saliency(img, saliency):

  saliency_new = saliency[:, :, np.newaxis]
  mult = img * saliency_new
  
  fig, axes = plt.subplots(1, 3, figsize=(15, 13))

  axes[0].imshow(img)
  axes[0].axis('off')
  axes[1].imshow(saliency, cmap="bwr")
  axes[1].axis('off')
  axes[2].imshow(mult)
  axes[2].axis('off')

#example for a single image, but this approach also works for average images

#pick an image 
img = dataset[cluster_index[2][1]]

#calculate the saliency map for this image 
sal = get_saliency(img)

#show the superimposed approach
show_new_saliency(avg2_1, sal)
